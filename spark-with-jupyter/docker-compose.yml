#version: '3.1'

networks:
    spark-cluster-net:
        driver: bridge

services:

  master:
    build: ./Master
    image: kamehouse0/spark-and-jupyter-master:latest
    container_name: spark-master
    hostname: spark-master
    command: /opt/bd/start-daemons-master.sh
    ports:
        - "9870:9870"
        - "8020:8020"
        - "9000:9000"
        - "8888:8888"
    volumes:
        - /home/popos/Documentos/0-PERSONAL/academico/IABD/compartidaDocker:/home/compartido
    networks:
        - spark-cluster-net

  resourcemanager:
    build: ./ResourceManager
    image: kamehouse0/spark-and-jupyter-resourcemanager:latest
    container_name: spark-resourcemanager
    hostname: spark-resourcemanager
    command: /opt/bd/start-daemons-resourcemanager.sh
    ports:
        - "8088:8088"
    networks:
        - spark-cluster-net

  worker1:
    build: ./Worker
    image: kamehouse0/spark-and-jupyter-worker:latest
    container_name: sw1
    hostname: sw1
    #restart: always
    ports:
      - 9866:9866
      - 9864:9864
    depends_on:
      - master
    command: /opt/bd/start-daemons-worker.sh
    networks:
      - spark-cluster-net
    environment:
      SERVICE_PRECONDITION: "spark-master:7077"

  worker2:
    build: ./Worker
    image: kamehouse0/spark-and-jupyter-worker:latest
    container_name: sw2
    hostname: sw2
    #restart: always
    ports:
      - 9867:9866
      - 9863:9864
    depends_on:
      - master
    command: /opt/bd/start-daemons-worker.sh
    networks:
      - spark-cluster-net
    environment:
      SERVICE_PRECONDITION: "spark-master:7077"

  worker3:
    build: ./Worker
    image: kamehouse0/spark-and-jupyter-worker:latest
    container_name: sw3
    hostname: sw3
    #restart: always
    ports:
        - 9868:9868
        - 9865:9864
    depends_on:
        - master
    command: /opt/bd/start-daemons-worker.sh
    networks:
        - spark-cluster-net
    environment:
       SERVICE_PRECONDITION: "spark-master:7077"
    


